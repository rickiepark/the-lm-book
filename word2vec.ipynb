{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rickiepark/the-lm-book/blob/main/bow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "621044ac-05ee-420b-ba31-bc6e6d36b570",
      "metadata": {
        "id": "621044ac-05ee-420b-ba31-bc6e6d36b570"
      },
      "source": [
        "<div style=\"display: flex; justify-content: center;\">\n",
        "    <div style=\"background-color: #f4f6f7; padding: 15px; width: 80%;\">\n",
        "        <table style=\"width: 100%\">\n",
        "            <tr>\n",
        "                <td style=\"vertical-align: middle;\">\n",
        "                    <span style=\"font-size: 14px;\">\n",
        "                        <a href=\"https://tensorflow.blog/the-lm-book\" target=\"_blank\" rel=\"noopener\"><대규모 언어 모델, 핵심만 빠르게!>(인사이트, 2025)</a>의 주피터 노트북<br><br>\n",
        "                        코드 저장소: <a href=\"https://github.com/rickiepark/the-lm-book\" target=\"_blank\" rel=\"noopener\">https://github.com/rickiepark/the-lm-book</a>\n",
        "                    </span>\n",
        "                </td>\n",
        "                <td style=\"vertical-align: middle;\">\n",
        "                    <a href=\"https://www.thelmbook.com\" target=\"_blank\" rel=\"noopener\">\n",
        "                        <img src=\"https://tensorflow.blog/wp-content/uploads/2025/10/cover-the-lm-book.jpg\" width=\"80px\" alt=\"대규모 언어 모델, 핵심만 빠르게!\" border=\"1\">\n",
        "                    </a>\n",
        "                </td>\n",
        "            </tr>\n",
        "        </table>\n",
        "    </div>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1ebf0200-475c-4b6d-ae9b-ad22f6b04ef0",
      "metadata": {
        "id": "1ebf0200-475c-4b6d-ae9b-ad22f6b04ef0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2edb2906-e4a1-433f-9795-70c5d7956c74"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7ae0577756b0>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import re, torch\n",
        "import torch.nn as nn\n",
        "\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "말뭉치 `docs`와 타깃 레이블 `label`을 수동으로 만듭니다. 전체 클래스 개수는 3개입니다."
      ],
      "metadata": {
        "id": "BCNV3xolqnCK"
      },
      "id": "BCNV3xolqnCK"
    },
    {
      "cell_type": "code",
      "source": [
        "docs = [\n",
        "    \"Movies are fun for everyone.\",\n",
        "    \"Watching movies is great fun.\",\n",
        "    \"Enjoy a great movie today.\",\n",
        "    \"Research is interesting and important.\",\n",
        "    \"Learning math is very important.\",\n",
        "    \"Science discovery is interesting.\",\n",
        "    \"Rock is great to listen to.\",\n",
        "    \"Listen to music for fun.\",\n",
        "    \"Music is fun for everyone.\",\n",
        "    \"Listen to folk music!\"\n",
        "]\n",
        "\n",
        "labels = [1, 1, 1, 3, 3, 3, 2, 2, 2, 2]\n",
        "num_classes = len(set(labels))\n",
        "\n",
        "num_classes"
      ],
      "metadata": {
        "id": "qNhjah0bdBAu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6256bd22-8067-4025-c1c2-2cb7421df2f9"
      },
      "id": "qNhjah0bdBAu",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "파이썬 정규식을 사용해 텍스트를 단순하게 공백을 기준으로 단어로 분리합니다."
      ],
      "metadata": {
        "id": "ieLACMLQqzEN"
      },
      "id": "ieLACMLQqzEN"
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "    return re.findall(r\"\\w+\", text.lower())"
      ],
      "metadata": {
        "id": "pWXOEtc9m4HE"
      },
      "id": "pWXOEtc9m4HE",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize(docs[0])"
      ],
      "metadata": {
        "id": "aTNuachKq5Ch",
        "outputId": "e1a441c4-bf7a-4789-f93c-166ee84675c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "aTNuachKq5Ch",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['movies', 'are', 'fun', 'for', 'everyone']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`texts`를 순회하면서 각 텍스트에서 모든 단어(토큰)을 추출합니다. 고유한 단어 모음을 만들기 위해 파이썬의 집합 컴프리헨션을 사용합니다.\n",
        "\n",
        "그다음 집합의 원소를 알파벳 순으로 정렬하여 인덱스를 부여하는 작업을 딕셔너리 컴프리헨션으로 수행합니다. 결과적으로 `단어:인덱스`의 딕셔너리가 생성됩니다."
      ],
      "metadata": {
        "id": "jEXaaaMArDlp"
      },
      "id": "jEXaaaMArDlp"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vocabulary(texts):\n",
        "    tokens = {token for text in texts for token in tokenize(text)}\n",
        "    return {word: idx for idx, word in enumerate(sorted(tokens))}"
      ],
      "metadata": {
        "id": "5g3yESgcm-Qc"
      },
      "id": "5g3yESgcm-Qc",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = get_vocabulary(docs)\n",
        "vocabulary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-nXBqJVnHGc",
        "outputId": "cd4eedfa-646b-4075-9b22-d8e889fa05da"
      },
      "id": "y-nXBqJVnHGc",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a': 0,\n",
              " 'and': 1,\n",
              " 'are': 2,\n",
              " 'discovery': 3,\n",
              " 'enjoy': 4,\n",
              " 'everyone': 5,\n",
              " 'folk': 6,\n",
              " 'for': 7,\n",
              " 'fun': 8,\n",
              " 'great': 9,\n",
              " 'important': 10,\n",
              " 'interesting': 11,\n",
              " 'is': 12,\n",
              " 'learning': 13,\n",
              " 'listen': 14,\n",
              " 'math': 15,\n",
              " 'movie': 16,\n",
              " 'movies': 17,\n",
              " 'music': 18,\n",
              " 'research': 19,\n",
              " 'rock': 20,\n",
              " 'science': 21,\n",
              " 'to': 22,\n",
              " 'today': 23,\n",
              " 'very': 24,\n",
              " 'watching': 25}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "텍스트를 입력 받으면 어휘사전 길이의 벡터를 생성하고 어휘사전에 등장하는 단어 위치를 1로 설정하는 함수를 만듭니다."
      ],
      "metadata": {
        "id": "8E1_laEBr4jv"
      },
      "id": "8E1_laEBr4jv"
    },
    {
      "cell_type": "code",
      "source": [
        "def doc_to_bow(doc, vocabulary):\n",
        "    tokens = set(tokenize(doc))\n",
        "    bow = [0] * len(vocabulary)\n",
        "    for token in tokens:\n",
        "        if token in vocabulary:\n",
        "            bow[vocabulary[token]] = 1\n",
        "    return bow"
      ],
      "metadata": {
        "id": "9bkaF3PHnK5M"
      },
      "id": "9bkaF3PHnK5M",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "말뭉치에 있는 모든 텍스트를 `doc_to_bow` 함수를 사용해 문서 단어 행렬로 만듭니다. 레이블을 텐서로 변환합니다."
      ],
      "metadata": {
        "id": "_4C1Ymg-sHhs"
      },
      "id": "_4C1Ymg-sHhs"
    },
    {
      "cell_type": "code",
      "source": [
        "vectors = torch.tensor(\n",
        "    [doc_to_bow(doc, vocabulary) for doc in docs],\n",
        "    dtype=torch.float32\n",
        ")\n",
        "labels = torch.tensor(labels, dtype=torch.long) - 1"
      ],
      "metadata": {
        "id": "H9QMz6ESnZkE"
      },
      "id": "H9QMz6ESnZkE",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`vectors`는 문서 단어 행렬입니다."
      ],
      "metadata": {
        "id": "T9WgplIqqeGS"
      },
      "id": "T9WgplIqqeGS"
    },
    {
      "cell_type": "code",
      "source": [
        "vectors"
      ],
      "metadata": {
        "id": "U1JIYsBXqUHB",
        "outputId": "25fa2931-96ce-4378-f504-8a93f9382e80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "U1JIYsBXqUHB",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "        [1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "         0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
              "         0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
              "         0., 0., 1., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "         1., 0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "         1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "         1., 0., 0., 0., 1., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "신경망의 입력 크기는 어휘사전의 크기에 해당합니다."
      ],
      "metadata": {
        "id": "oZPNIq-EsRHu"
      },
      "id": "oZPNIq-EsRHu"
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = len(vocabulary)\n",
        "hidden_dim = 50\n",
        "output_dim = num_classes\n",
        "\n",
        "input_dim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvnQ5jkLnjl-",
        "outputId": "31d3ba5d-52d5-49b2-84c2-8c4c275d807e"
      },
      "id": "xvnQ5jkLnjl-",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "다중 분류에서 마지막 층의 활성화 함수는 소프트맥스 함수를 사용합니다.\n",
        "\n",
        "$\\text{softmax}(\\mathbf{z}, k) = \\dfrac{e^{z_k}}{\\displaystyle \\sum_{j=1}^D e^{z_j}}$\n",
        "\n",
        "파이토치에서 신경망에 소프트맥스 활성화 함수를 사용하는 경우 `NLLLoss` 손실 함수를 사용하고, 활성화 함수를 생략하는 경우 `CrossEntropyLoss`를 사용합니다."
      ],
      "metadata": {
        "id": "ev09MgYMs9fT"
      },
      "id": "ev09MgYMs9fT"
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleClassifier(input_dim, hidden_dim, output_dim)"
      ],
      "metadata": {
        "id": "chG0NKbyoowo"
      },
      "id": "chG0NKbyoowo",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "크로스 엔트로피 함수를 로지스틱 손실의 다중 분류 버전으로 생각할 수 있습니다.\n",
        "\n",
        "$\\text{loss}(\\mathbf{\\tilde{y}}, \\mathbf{y}) = -\\displaystyle \\sum_{k=1}^{C} y^{(k)}\\text{log}(\\tilde{y}^{(k)})$"
      ],
      "metadata": {
        "id": "hMSi9OE0vl9c"
      },
      "id": "hMSi9OE0vl9c"
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "for step in range(3000):\n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(model(vectors), labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "Q2LXZ6vio5fU"
      },
      "id": "Q2LXZ6vio5fU",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_docs = [\n",
        "    \"Listening to rock music is fun.\",\n",
        "    \"I love science very much.\"\n",
        "]\n",
        "class_names = [\"Cinema\", \"Music\", \"Science\"]"
      ],
      "metadata": {
        "id": "FnmtiuAopRp0"
      },
      "id": "FnmtiuAopRp0",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_doc_vectors = torch.tensor(\n",
        "    [doc_to_bow(new_doc, vocabulary) for new_doc in new_docs],\n",
        "    dtype=torch.float32\n",
        ")\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(new_doc_vectors)\n",
        "    predicted_ids = torch.argmax(outputs, dim=1) + 1\n",
        "\n",
        "for i, new_doc in enumerate(new_docs):\n",
        "    print(f'{new_doc}: {class_names[predicted_ids[i].item() - 1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHGd1jlfpa7R",
        "outputId": "92e72426-21a9-4686-a075-9de7d3f78941"
      },
      "id": "eHGd1jlfpa7R",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Listening to rock music is fun.: Music\n",
            "I love science very much.: Science\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}