{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/rickiepark/the-lm-book/blob/main/emotion_GPT2_as_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LpCleINoAMtW"
   },
   "source": [
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <div style=\"background-color: #f4f6f7; padding: 15px; width: 80%;\">\n",
    "        <table style=\"width: 100%\">\n",
    "            <tr>\n",
    "                <td style=\"vertical-align: middle;\">\n",
    "                    <span style=\"font-size: 14px;\">\n",
    "                        <a href=\"https://tensorflow.blog/the-lm-book\" target=\"_blank\" rel=\"noopener\"><대규모 언어 모델, 핵심만 빠르게!>(인사이트, 2025)</a>의 주피터 노트북<br><br>\n",
    "                        코드 저장소: <a href=\"https://github.com/rickiepark/the-lm-book\" target=\"_blank\" rel=\"noopener\">https://github.com/rickiepark/the-lm-book</a>\n",
    "                    </span>\n",
    "                </td>\n",
    "                <td style=\"vertical-align: middle;\">\n",
    "                    <a href=\"https://www.thelmbook.com\" target=\"_blank\" rel=\"noopener\">\n",
    "                        <img src=\"https://tensorflow.blog/wp-content/uploads/2025/10/cover-the-lm-book.jpg\" width=\"80px\" alt=\"대규모 언어 모델, 핵심만 빠르게!\" border=\"1\">\n",
    "                    </a>\n",
    "                </td>\n",
    "            </tr>\n",
    "        </table>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yy0zjL_2ouOU"
   },
   "outputs": [],
   "source": [
    "# 필수 라이브러리 임포트\n",
    "import torch           # 메인 파이토치 라이브러리\n",
    "from torch.utils.data import DataLoader  # 데이터셋 처리를 위한 라이브러리\n",
    "from torch.optim import AdamW    # 훈련을 위한 옵티마이저\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification  # 허깅 페이스 구성 요소\n",
    "from tqdm import tqdm   # 진행률 표시줄 유틸리티\n",
    "import json             # JSON 데이터 구문 분석을 위한 라이브러리\n",
    "import requests         # URL에서 데이터셋 다운로드를 위한 라이브러리\n",
    "import gzip             # 데이터셋 압축 해제를 위한 라이브러리\n",
    "import random           # 시드 설정 및 데이터 셔플링을 위한 라이브러리\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    다양한 라이브러리에서 재현성을 위해 난수 시드를 설정합니다.\n",
    "    Args:\n",
    "        seed (int): 난수 생성을 위한 시드 값\n",
    "    \"\"\"\n",
    "    # 파이썬 내장 random 시드 설정\n",
    "    random.seed(seed)\n",
    "    # 파이토치 CPU 난수 시드 설정\n",
    "    torch.manual_seed(seed)\n",
    "    # 사용 가능한 모든 GPU에 대한 시드 설정\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    # cuDNN이 결정론적 알고리즘을 사용하도록 요청\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    # 일관된 동작을 위해 cuDNN의 자동 튜너 비활성화\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def load_and_split_dataset(url, test_ratio=0.1):\n",
    "    \"\"\"\n",
    "    데이터셋을 다운로드하고 훈련 및 테스트 세트로 분할합니다.\n",
    "    Args:\n",
    "        url (str): 데이터셋의 URL\n",
    "        test_ratio (float): 테스트를 위한 데이터 비율\n",
    "    Returns:\n",
    "        tuple: (train_dataset, test_dataset)\n",
    "    \"\"\"\n",
    "    # 데이터셋 다운로드 및 압축 해제\n",
    "    response = requests.get(url)\n",
    "    content = gzip.decompress(response.content).decode()\n",
    "    # JSON 라인을 예시 목록으로 구문 분석\n",
    "    dataset = [json.loads(line) for line in content.splitlines()]\n",
    "    # 데이터셋 셔플 및 분할\n",
    "    random.shuffle(dataset)\n",
    "    split_index = int(len(dataset) * (1 - test_ratio))\n",
    "    return dataset[:split_index], dataset[split_index:]\n",
    "\n",
    "def encode_text(tokenizer, text, return_tensor=False):\n",
    "    \"\"\"\n",
    "    제공된 토크나이저를 사용하여 텍스트를 인코딩합니다.\n",
    "    Args:\n",
    "        tokenizer: 허깅 페이스 토크나이저\n",
    "        text (str): 인코딩할 텍스트\n",
    "        return_tensor (bool): 파이토치 텐서를 반환할지 여부\n",
    "    Returns:\n",
    "        토큰 ID의 목록 또는 텐서\n",
    "    \"\"\"\n",
    "    # 텐서 출력이 요청된 경우, 파이토치 텐서로 인코딩\n",
    "    if return_tensor:\n",
    "        return tokenizer.encode(\n",
    "            text, add_special_tokens=False, return_tensors=\"pt\"\n",
    "        )\n",
    "    # 그렇지 않으면 토큰 ID 목록 반환\n",
    "    else:\n",
    "        return tokenizer.encode(text, add_special_tokens=False)\n",
    "\n",
    "class TextClassificationDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    텍스트 분류를 위한 파이토치 데이터셋.\n",
    "    텍스트와 레이블을 모델 준비 형식으로 변환합니다.\n",
    "    Args:\n",
    "        data (list): 텍스트와 레이블을 포함하는 사전 목록\n",
    "        tokenizer: 허깅 페이스 토크나이저\n",
    "        label_to_id (dict): 레이블 문자열에서 ID로의 매핑\n",
    "    \"\"\"\n",
    "    def __init__(self, data, tokenizer, label_to_id):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.label_to_id = label_to_id\n",
    "\n",
    "    def __len__(self):\n",
    "        # 총 예시 수 반환\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        단일 훈련 예시를 반환합니다.\n",
    "        Args:\n",
    "            idx (int): 가져올 예시의 인덱스\n",
    "        Returns:\n",
    "            dict: input_ids와 labels를 포함\n",
    "        \"\"\"\n",
    "        # 데이터셋에서 예시 가져오기\n",
    "        item = self.data[idx]\n",
    "        # 텍스트를 토큰 ID로 변환\n",
    "        input_ids = encode_text(self.tokenizer, item[\"text\"])\n",
    "        # 레이블 문자열을 ID로 변환\n",
    "        labels = self.label_to_id[item[\"label\"]]\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"labels\": labels\n",
    "        }\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    예시 배치를 훈련 준비 형식으로 통합합니다.\n",
    "    패딩과 텐서 변환을 처리합니다.\n",
    "    Args:\n",
    "        batch: 데이터셋의 예시 목록\n",
    "    Returns:\n",
    "        dict: input_ids, labels, attention_mask 텐서를 포함\n",
    "    \"\"\"\n",
    "    # 패딩을 위해 가장 긴 시퀀스 찾기\n",
    "    max_length = max(len(item[\"input_ids\"]) for item in batch)\n",
    "    # 0으로 입력 시퀀스 패딩\n",
    "    input_ids = [\n",
    "        item[\"input_ids\"] +\n",
    "        [0] * (max_length - len(item[\"input_ids\"]))\n",
    "        for item in batch\n",
    "    ]\n",
    "    # 어텐션 마스크 생성 (토큰은 1, 패딩은 0)\n",
    "    attention_mask = [\n",
    "        [1] * len(item[\"input_ids\"]) +\n",
    "        [0] * (max_length - len(item[\"input_ids\"]))\n",
    "        for item in batch\n",
    "    ]\n",
    "    # 레이블 수집\n",
    "    labels = [item[\"labels\"] for item in batch]\n",
    "    # 모든 항목을 텐서로 변환\n",
    "    return {\n",
    "        \"input_ids\": torch.tensor(input_ids),\n",
    "        \"labels\": torch.tensor(labels),\n",
    "        \"attention_mask\": torch.tensor(attention_mask)\n",
    "    }\n",
    "\n",
    "def generate_label(model, tokenizer, text):\n",
    "    \"\"\"\n",
    "    입력 텍스트에 대한 레이블 예측을 생성합니다.\n",
    "    Args:\n",
    "        model: 미세 튜닝된 모델\n",
    "        tokenizer: 연관된 토크나이저\n",
    "        text (str): 분류할 입력 텍스트\n",
    "    Returns:\n",
    "        str: 예측된 레이블\n",
    "    \"\"\"\n",
    "    # 텍스트 인코딩 및 모델 장치로 이동\n",
    "    input_ids = encode_text(\n",
    "        tokenizer,\n",
    "        text,\n",
    "        return_tensor=True\n",
    "    ).to(model.device)\n",
    "    # 모델 예측 가져오기\n",
    "    outputs = model(input_ids)\n",
    "    logits = outputs.logits[0]\n",
    "    # 가장 높은 확률의 클래스 가져오기\n",
    "    predicted_class = logits.argmax().item()\n",
    "    # 클래스 ID를 레이블 문자열로 변환\n",
    "    return model.config.id2label[predicted_class]\n",
    "\n",
    "def calculate_accuracy(model, dataloader):\n",
    "    \"\"\"\n",
    "    데이터셋에서 예측 정확도를 계산합니다.\n",
    "    Args:\n",
    "        model: 미세 튜닝된 모델\n",
    "        dataloader: 평가 예시를 포함하는 DataLoader\n",
    "    Returns:\n",
    "        float: 정확도 점수\n",
    "    \"\"\"\n",
    "    # 모델을 평가 모드로 설정\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # 효율성을 위해 그레이디언트 계산 비활성화\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            # 배치를 장치로 이동\n",
    "            input_ids = batch[\"input_ids\"].to(model.device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(model.device)\n",
    "            labels = batch[\"labels\"].to(model.device)\n",
    "            # 모델 예측 가져오기\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            predictions = outputs.logits.argmax(dim=-1)\n",
    "            # 정확도 카운터 업데이트\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    # 정확도 계산\n",
    "    accuracy = correct / total\n",
    "    # 모델을 훈련 모드로 재설정\n",
    "    model.train()\n",
    "    return accuracy\n",
    "\n",
    "def create_label_mappings(train_dataset):\n",
    "    \"\"\"\n",
    "    레이블 문자열과 ID 사이의 매핑을 생성합니다.\n",
    "    Args:\n",
    "        train_dataset: 훈련 예시 목록\n",
    "    Returns:\n",
    "        tuple: (label_to_id, id_to_label, unique_labels)\n",
    "    \"\"\"\n",
    "    # 정렬된 고유 레이블 목록 가져오기\n",
    "    unique_labels = sorted(set(item[\"label\"] for item in train_dataset))\n",
    "    # 레이블과 ID 사이의 매핑 생성\n",
    "    label_to_id = {label: i for i, label in enumerate(unique_labels)}\n",
    "    id_to_label = {i: label for label, i in label_to_id.items()}\n",
    "    return label_to_id, id_to_label, unique_labels\n",
    "\n",
    "def test_model(model_path, test_input):\n",
    "    \"\"\"\n",
    "    저장된 모델을 단일 입력으로 테스트합니다.\n",
    "    Args:\n",
    "        model_path (str): 저장된 모델의 경로\n",
    "        test_input (str): 분류할 텍스트\n",
    "    \"\"\"\n",
    "    # 장치 설정 및 모델 로드\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path).to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    # 예측 생성 및 표시\n",
    "    emotion = generate_label(model, tokenizer, test_input)\n",
    "    print(f\"입력: {test_input}\")\n",
    "    print(f\"예측된 감정: {emotion}\")\n",
    "\n",
    "def download_and_prepare_data(data_url, tokenizer, batch_size):\n",
    "    \"\"\"\n",
    "    훈련을 위해 데이터셋을 다운로드하고 준비합니다.\n",
    "    Args:\n",
    "        data_url (str): 데이터셋의 URL\n",
    "        tokenizer: 텍스트 처리를 위한 토크나이저\n",
    "        batch_size (int): DataLoader의 배치 크기\n",
    "    Returns:\n",
    "        tuple: (train_dataloader, test_dataloader, label_to_id, id_to_label, unique_labels)\n",
    "    \"\"\"\n",
    "    # 데이터셋 로드 및 분할\n",
    "    train_dataset, test_dataset = load_and_split_dataset(data_url)\n",
    "    # 레이블 매핑 생성\n",
    "    label_to_id, id_to_label, unique_labels = create_label_mappings(train_dataset)\n",
    "    # 데이터셋 생성\n",
    "    train_data = TextClassificationDataset(\n",
    "        train_dataset,\n",
    "        tokenizer,\n",
    "        label_to_id\n",
    "    )\n",
    "    test_data = TextClassificationDataset(\n",
    "        test_dataset,\n",
    "        tokenizer,\n",
    "        label_to_id\n",
    "    )\n",
    "    # 데이터로더 생성\n",
    "    train_dataloader = DataLoader(\n",
    "        train_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    test_dataloader = DataLoader(\n",
    "        test_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    return train_dataloader, test_dataloader, label_to_id, id_to_label, unique_labels\n",
    "\n",
    "def get_hyperparameters():\n",
    "    \"\"\"\n",
    "    훈련 하이퍼파라미터를 반환합니다.\n",
    "    Returns:\n",
    "        tuple: (num_epochs, batch_size, learning_rate)\n",
    "    \"\"\"\n",
    "    # 시퀀스 분류가 더 빨리 수렴하므로 더 적은 에포크로 훈련\n",
    "    num_epochs=8\n",
    "    # 대부분의 GPU 메모리에서 잘 작동하는 표준 배치 크기\n",
    "    batch_size=16\n",
    "    # 트랜스포머 미세 튜닝을 위한 표준 학습률\n",
    "    learning_rate=5e-5\n",
    "    return num_epochs, batch_size, learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 611,
     "referenced_widgets": [
      "cde21c2f80724fa59af5b543c3df2313",
      "30f261207c304cd3a9ca278f61bfcd27",
      "76984d6f579941b6a051865cb539f2e8",
      "fb37fb15ec8e41628a56437d3604b0bf",
      "91d3b5bd749240949500fa8af86dbf21",
      "d29a36ab504842178b9871ff2f410a93",
      "7377de1655ca4367a1975a28a9089fbb",
      "c9124c9aa047459e81ecdc36a23b10a4",
      "0dedff9f1c3b4f0e8dead031e53c284f",
      "6bb40c725a1740319f460c196d96633e",
      "7b6ab6a83cdb402399920452fb10253c",
      "227574483f984899a4e370bce9fe18be",
      "fb78c267cc8f4bb8b566d016be5142b9",
      "a1bf2cd839634946bd034d38887b432a",
      "0b397401ad5445fbbd0abc65f8b85cfe",
      "748ba76be6c742d2ac0b3c0ecdea2170",
      "4634f2065fc042e18f1211402b50f8f3",
      "c33d4cb8397d48d280501df7420a1eaf",
      "22d49fb12cec4c51b6ad6906f8a0fd0f",
      "2ef65451a4bc445c901b429a255d9188",
      "a8fd77cfe4c1423a9e190c60c7f9fa7f",
      "9b481d538d3c49878acb1baf767d64f1",
      "1360fcedeb954698aca8187d7d9184cd",
      "d4cea9e3371640fd8d32a8aa27b32de7",
      "7cd35a5cafa648c18e18a67436993a28",
      "a004cb00fad547f0bf0339ff65151882",
      "502f30a6e58d44c4ae3024d5aeeee893",
      "1ea405569d8b4fe69d81dcdc8d7d3254",
      "c97349d62d054385be9f1beab2837431",
      "89752e2cf0e7489e8696959bf1c0097b",
      "f0c9bb97bcca43a690f7480fec181045",
      "cb60fa7fab2541718c541912b975d903",
      "b437fe64a79f4b04b5a5353241ad87b0",
      "16067913fa6d4624b3786ba136ea449f",
      "9a69c67f11cb43a694ad6d53b2ee395d",
      "fe58f56f9d82486ea6abf25b1fe35bb9",
      "67a5115db30c4e3c8edfb7a7cb469793",
      "1ccd538bcba44ebf9642c9454a6e70a9",
      "9c5e15683b0a475d88f3905eece1c6aa",
      "9814c1462baa40faa62c731e804c67fa",
      "30d77619ad204853b711085d88d5957a",
      "68be214d9f8749c783a328e3cdb40e42",
      "249653abcf8b4753be7960cf7f449071",
      "a0932b86e95e4f418f453e58fce20ee7",
      "20cf498fdd7547d0b0b854e647baca1e",
      "bb7129b78aff45618d0fac5e349ec5f2",
      "e09a19c1e672407c96853cc1a5276a4e",
      "62c64231ad9345c1b9a42ffd9f6c3701",
      "d613227e96564f97a26e60ac1a3359ae",
      "c7da018e3af644fbb5f6afd870157d34",
      "b901de6f3c83406eba2be9050bd8f85d",
      "ca5487bffd0846a1a81f29c231bc15e3",
      "f7b1ccf6a3fc436e9f2a5cb5d984d8df",
      "04fb68fdabe547c5896ed9e6c351cbc3",
      "a557e4ba92c74525bdba4e8fd111e23e",
      "ba1dfd1610d54c95803d39ba045769a7",
      "68b40af9d3fb472ca4fb8c20aa5d2dd2",
      "21ce20ca4c6f4fb9b4e6925ff79ab62c",
      "51f03035f6a9405e898cafa847f0cc49",
      "ca86af4094e049cc81a2806cc504b6d1",
      "091306b3dc924d64b0f5c6996593cea1",
      "5951c9177cd9413ba390536ee9f710e9",
      "eecefbae882349b69945d9aaa31d8a6f",
      "e57d7e436f1440faa2a5fe4a79c08afe",
      "0ae133734ca4403e89a1f814d31221b2",
      "da665d68a5194d69a8d30ae011182b9e"
     ]
    },
    "id": "tV5env80jwuf",
    "outputId": "720b74dc-09f2-4b3c-9cff-430584069cfc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde21c2f80724fa59af5b543c3df2313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "227574483f984899a4e370bce9fe18be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1360fcedeb954698aca8187d7d9184cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16067913fa6d4624b3786ba136ea449f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20cf498fdd7547d0b0b854e647baca1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba1dfd1610d54c95803d39ba045769a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "에포크 1/8: 100%|██████████| 1125/1125 [00:57<00:00, 19.58it/s, 손실=0.488]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 손실: 0.4882, 테스트 정확도: 0.9230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "에포크 2/8: 100%|██████████| 1125/1125 [00:55<00:00, 20.41it/s, 손실=0.144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 손실: 0.1437, 테스트 정확도: 0.9310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "에포크 3/8: 100%|██████████| 1125/1125 [00:54<00:00, 20.54it/s, 손실=0.115]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 손실: 0.1149, 테스트 정확도: 0.9410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "에포크 4/8: 100%|██████████| 1125/1125 [00:54<00:00, 20.56it/s, 손실=0.104]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 손실: 0.1038, 테스트 정확도: 0.9395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "에포크 5/8: 100%|██████████| 1125/1125 [00:54<00:00, 20.55it/s, 손실=0.0963]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 손실: 0.0963, 테스트 정확도: 0.9340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "에포크 6/8: 100%|██████████| 1125/1125 [00:54<00:00, 20.50it/s, 손실=0.0851]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 손실: 0.0851, 테스트 정확도: 0.9395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "에포크 7/8: 100%|██████████| 1125/1125 [00:55<00:00, 20.44it/s, 손실=0.0806]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 손실: 0.0806, 테스트 정확도: 0.9400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "에포크 8/8: 100%|██████████| 1125/1125 [00:54<00:00, 20.60it/s, 손실=0.0767]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 손실: 0.0767, 테스트 정확도: 0.9460\n",
      "입력: I'm so happy to be able to finetune an LLM!\n",
      "예측된 감정: joy\n"
     ]
    }
   ],
   "source": [
    "# 재현성을 위해 난수 시드 설정\n",
    "seed = 42\n",
    "set_seed(seed)\n",
    "\n",
    "# 훈련 매개변수 구성\n",
    "data_url = \"https://www.thelmbook.com/data/emotions\"\n",
    "model_name = \"openai-community/gpt2\"\n",
    "\n",
    "# 하이퍼파라미터 가져오기\n",
    "num_epochs, batch_size, learning_rate = get_hyperparameters()\n",
    "\n",
    "# 장치 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 토크나이저 초기화\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 데이터 준비 및 레이블 매핑 가져오기\n",
    "train_loader, test_loader, label_to_id, id_to_label, unique_labels = download_and_prepare_data(\n",
    "    data_url,\n",
    "    tokenizer,\n",
    "    batch_size\n",
    ")\n",
    "\n",
    "# 시퀀스 분류를 위한 모델 초기화\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(unique_labels)\n",
    ").to(device)\n",
    "\n",
    "# 모델의 레이블 처리 구성\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "model.config.id2label = id_to_label\n",
    "model.config.label2id = label_to_id\n",
    "\n",
    "# 옵티마이저 초기화\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 훈련 루프\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"에포크 {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        # 배치를 장치로 이동\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        # 포워드 패스\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        # 백워드 패스 및 최적화\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 메트릭 업데이트\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        progress_bar.set_postfix({\"손실\": total_loss / num_batches})\n",
    "\n",
    "    # 에포크 메트릭 표시\n",
    "    avg_loss = total_loss / num_batches\n",
    "    test_acc = calculate_accuracy(model, test_loader)\n",
    "    print(f\"평균 손실: {avg_loss:.4f}, 테스트 정확도: {test_acc:.4f}\")\n",
    "\n",
    "# 미세 튜닝된 모델 저장\n",
    "model.save_pretrained(\"./finetuned_model\")\n",
    "tokenizer.save_pretrained(\"./finetuned_model\")\n",
    "\n",
    "# 모델 테스트\n",
    "test_input = \"I'm so happy to be able to finetune an LLM!\"\n",
    "test_model(\"./finetuned_model\", test_input)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
