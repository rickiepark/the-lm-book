{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/rickiepark/the-lm-book/blob/main/emotion_GPT2_as_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LpCleINoAMtW"
   },
   "source": [
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <div style=\"background-color: #f4f6f7; padding: 15px; width: 80%;\">\n",
    "        <table style=\"width: 100%\">\n",
    "            <tr>\n",
    "                <td style=\"vertical-align: middle;\">\n",
    "                    <span style=\"font-size: 14px;\">\n",
    "                        A notebook for <a href=\"https://www.thelmbook.com\" target=\"_blank\" rel=\"noopener\">The Hundred-Page Language Models Book</a> by Andriy Burkov<br><br>\n",
    "                        Code repository: <a href=\"https://github.com/rickiepark/the-lm-book\" target=\"_blank\" rel=\"noopener\">https://github.com/rickiepark/the-lm-book</a>\n",
    "                    </span>\n",
    "                </td>\n",
    "                <td style=\"vertical-align: middle;\">\n",
    "                    <a href=\"https://www.thelmbook.com\" target=\"_blank\" rel=\"noopener\">\n",
    "                        <img src=\"https://thelmbook.com/img/book.png\" width=\"80px\" alt=\"The Hundred-Page Language Models Book\">\n",
    "                    </a>\n",
    "                </td>\n",
    "            </tr>\n",
    "        </table>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yy0zjL_2ouOU"
   },
   "outputs": [],
   "source": [
    "# 필수 라이브러리 임포트\n",
    "import torch           # 메인 파이토치 라이브러리\n",
    "from torch.utils.data import DataLoader  # 데이터셋 처리를 위한 라이브러리\n",
    "from torch.optim import AdamW    # 훈련을 위한 옵티마이저\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification  # 허깅 페이스 구성 요소\n",
    "from tqdm import tqdm   # 진행률 표시줄 유틸리티\n",
    "import json             # JSON 데이터 구문 분석을 위한 라이브러리\n",
    "import requests         # URL에서 데이터셋 다운로드를 위한 라이브러리\n",
    "import gzip             # 데이터셋 압축 해제를 위한 라이브러리\n",
    "import random           # 시드 설정 및 데이터 셔플링을 위한 라이브러리\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    다양한 라이브러리에서 재현성을 위해 난수 시드를 설정합니다.\n",
    "    Args:\n",
    "        seed (int): 난수 생성을 위한 시드 값\n",
    "    \"\"\"\n",
    "    # 파이썬 내장 random 시드 설정\n",
    "    random.seed(seed)\n",
    "    # 파이토치 CPU 난수 시드 설정\n",
    "    torch.manual_seed(seed)\n",
    "    # 사용 가능한 모든 GPU에 대한 시드 설정\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    # cuDNN이 결정론적 알고리즘을 사용하도록 요청\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    # 일관된 동작을 위해 cuDNN의 자동 튜너 비활성화\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def load_and_split_dataset(url, test_ratio=0.1):\n",
    "    \"\"\"\n",
    "    데이터셋을 다운로드하고 훈련 및 테스트 세트로 분할합니다.\n",
    "    Args:\n",
    "        url (str): 데이터셋의 URL\n",
    "        test_ratio (float): 테스트를 위한 데이터 비율\n",
    "    Returns:\n",
    "        tuple: (train_dataset, test_dataset)\n",
    "    \"\"\"\n",
    "    # 데이터셋 다운로드 및 압축 해제\n",
    "    response = requests.get(url)\n",
    "    content = gzip.decompress(response.content).decode()\n",
    "    # JSON 라인을 예시 목록으로 구문 분석\n",
    "    dataset = [json.loads(line) for line in content.splitlines()]\n",
    "    # 데이터셋 셔플 및 분할\n",
    "    random.shuffle(dataset)\n",
    "    split_index = int(len(dataset) * (1 - test_ratio))\n",
    "    return dataset[:split_index], dataset[split_index:]\n",
    "\n",
    "def load_model_and_tokenizer(model_name, device, label_to_id, id_to_label, unique_labels):\n",
    "    \"\"\"\n",
    "    시퀀스 분류를 위한 모델과 토크나이저를 로드하고 구성합니다.\n",
    "    Args:\n",
    "        model_name (str): 사전 훈련된 모델의 이름\n",
    "        device: 모델을 로드할 장치\n",
    "        label_to_id (dict): 레이블 문자열에서 ID로의 매핑\n",
    "        id_to_label (dict): ID에서 레이블 문자열로의 매핑\n",
    "        unique_labels (list): 모든 가능한 레이블의 목록\n",
    "    Returns:\n",
    "        tuple: (model, tokenizer)\n",
    "    \"\"\"\n",
    "    # 올바른 수의 출력 클래스로 모델 초기화\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(unique_labels)\n",
    "    )\n",
    "    # 패딩 및 레이블 매핑 구성\n",
    "    model.config.pad_token_id = model.config.eos_token_id\n",
    "    model.config.id2label = id_to_label\n",
    "    model.config.label2id = label_to_id\n",
    "    # 토크나이저 초기화 및 구성\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    return (model.to(device), tokenizer)\n",
    "\n",
    "def encode_text(tokenizer, text, return_tensor=False):\n",
    "    \"\"\"\n",
    "    제공된 토크나이저를 사용하여 텍스트를 인코딩합니다.\n",
    "    Args:\n",
    "        tokenizer: 허깅 페이스 토크나이저\n",
    "        text (str): 인코딩할 텍스트\n",
    "        return_tensor (bool): 파이토치 텐서를 반환할지 여부\n",
    "    Returns:\n",
    "        토큰 ID의 목록 또는 텐서\n",
    "    \"\"\"\n",
    "    # 텐서 출력이 요청된 경우, 파이토치 텐서로 인코딩\n",
    "    if return_tensor:\n",
    "        return tokenizer.encode(\n",
    "            text, add_special_tokens=False, return_tensors=\"pt\"\n",
    "        )\n",
    "    # 그렇지 않으면 토큰 ID 목록 반환\n",
    "    else:\n",
    "        return tokenizer.encode(text, add_special_tokens=False)\n",
    "\n",
    "class TextClassificationDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    텍스트 분류를 위한 파이토치 데이터셋.\n",
    "    텍스트와 레이블을 모델 준비 형식으로 변환합니다.\n",
    "    Args:\n",
    "        data (list): 텍스트와 레이블을 포함하는 사전 목록\n",
    "        tokenizer: 허깅 페이스 토크나이저\n",
    "        label_to_id (dict): 레이블 문자열에서 ID로의 매핑\n",
    "    \"\"\"\n",
    "    def __init__(self, data, tokenizer, label_to_id):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.label_to_id = label_to_id\n",
    "\n",
    "    def __len__(self):\n",
    "        # 총 예시 수 반환\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        단일 훈련 예시를 반환합니다.\n",
    "        Args:\n",
    "            idx (int): 가져올 예시의 인덱스\n",
    "        Returns:\n",
    "            dict: input_ids와 labels를 포함\n",
    "        \"\"\"\n",
    "        # 데이터셋에서 예시 가져오기\n",
    "        item = self.data[idx]\n",
    "        # 텍스트를 토큰 ID로 변환\n",
    "        input_ids = encode_text(self.tokenizer, item[\"text\"])\n",
    "        # 레이블 문자열을 ID로 변환\n",
    "        labels = self.label_to_id[item[\"label\"]]\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"labels\": labels\n",
    "        }\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    예시 배치를 훈련 준비 형식으로 통합합니다.\n",
    "    패딩과 텐서 변환을 처리합니다.\n",
    "    Args:\n",
    "        batch: 데이터셋의 예시 목록\n",
    "    Returns:\n",
    "        dict: input_ids, labels, attention_mask 텐서를 포함\n",
    "    \"\"\"\n",
    "    # 패딩을 위해 가장 긴 시퀀스 찾기\n",
    "    max_length = max(len(item[\"input_ids\"]) for item in batch)\n",
    "    # 0으로 입력 시퀀스 패딩\n",
    "    input_ids = [\n",
    "        item[\"input_ids\"] +\n",
    "        [0] * (max_length - len(item[\"input_ids\"]))\n",
    "        for item in batch\n",
    "    ]\n",
    "    # 어텐션 마스크 생성 (토큰은 1, 패딩은 0)\n",
    "    attention_mask = [\n",
    "        [1] * len(item[\"input_ids\"]) +\n",
    "        [0] * (max_length - len(item[\"input_ids\"]))\n",
    "        for item in batch\n",
    "    ]\n",
    "    # 레이블 수집\n",
    "    labels = [item[\"labels\"] for item in batch]\n",
    "    # 모든 항목을 텐서로 변환\n",
    "    return {\n",
    "        \"input_ids\": torch.tensor(input_ids),\n",
    "        \"labels\": torch.tensor(labels),\n",
    "        \"attention_mask\": torch.tensor(attention_mask)\n",
    "    }\n",
    "\n",
    "def generate_label(model, tokenizer, text):\n",
    "    \"\"\"\n",
    "    입력 텍스트에 대한 레이블 예측을 생성합니다.\n",
    "    Args:\n",
    "        model: 미세 튜닝된 모델\n",
    "        tokenizer: 연관된 토크나이저\n",
    "        text (str): 분류할 입력 텍스트\n",
    "    Returns:\n",
    "        str: 예측된 레이블\n",
    "    \"\"\"\n",
    "    # 텍스트 인코딩 및 모델 장치로 이동\n",
    "    input_ids = encode_text(\n",
    "        tokenizer,\n",
    "        text,\n",
    "        return_tensor=True\n",
    "    ).to(model.device)\n",
    "    # 모델 예측 가져오기\n",
    "    outputs = model(input_ids)\n",
    "    logits = outputs.logits[0]\n",
    "    # 가장 높은 확률의 클래스 가져오기\n",
    "    predicted_class = logits.argmax().item()\n",
    "    # 클래스 ID를 레이블 문자열로 변환\n",
    "    return model.config.id2label[predicted_class]\n",
    "\n",
    "def calculate_accuracy(model, dataloader):\n",
    "    \"\"\"\n",
    "    데이터셋에서 예측 정확도를 계산합니다.\n",
    "    Args:\n",
    "        model: 미세 튜닝된 모델\n",
    "        dataloader: 평가 예시를 포함하는 DataLoader\n",
    "    Returns:\n",
    "        float: 정확도 점수\n",
    "    \"\"\"\n",
    "    # 모델을 평가 모드로 설정\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # 효율성을 위해 그레이디언트 계산 비활성화\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            # 배치를 장치로 이동\n",
    "            input_ids = batch[\"input_ids\"].to(model.device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(model.device)\n",
    "            labels = batch[\"labels\"].to(model.device)\n",
    "            # 모델 예측 가져오기\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            predictions = outputs.logits.argmax(dim=-1)\n",
    "            # 정확도 카운터 업데이트\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    # 정확도 계산\n",
    "    accuracy = correct / total\n",
    "    # 모델을 훈련 모드로 재설정\n",
    "    model.train()\n",
    "    return accuracy\n",
    "\n",
    "def create_label_mappings(train_dataset):\n",
    "    \"\"\"\n",
    "    레이블 문자열과 ID 사이의 매핑을 생성합니다.\n",
    "    Args:\n",
    "        train_dataset: 훈련 예시 목록\n",
    "    Returns:\n",
    "        tuple: (label_to_id, id_to_label, unique_labels)\n",
    "    \"\"\"\n",
    "    # 정렬된 고유 레이블 목록 가져오기\n",
    "    unique_labels = sorted(set(item[\"label\"] for item in train_dataset))\n",
    "    # 레이블과 ID 사이의 매핑 생성\n",
    "    label_to_id = {label: i for i, label in enumerate(unique_labels)}\n",
    "    id_to_label = {i: label for label, i in label_to_id.items()}\n",
    "    return label_to_id, id_to_label, unique_labels\n",
    "\n",
    "def test_model(model_path, test_input):\n",
    "    \"\"\"\n",
    "    저장된 모델을 단일 입력으로 테스트합니다.\n",
    "    Args:\n",
    "        model_path (str): 저장된 모델의 경로\n",
    "        test_input (str): 분류할 텍스트\n",
    "    \"\"\"\n",
    "    # 장치 설정 및 모델 로드\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path).to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    # 예측 생성 및 표시\n",
    "    emotion = generate_label(model, tokenizer, test_input)\n",
    "    print(f\"입력: {test_input}\")\n",
    "    print(f\"예측된 감정: {emotion}\")\n",
    "\n",
    "def download_and_prepare_data(data_url, tokenizer, batch_size):\n",
    "    \"\"\"\n",
    "    훈련을 위해 데이터셋을 다운로드하고 준비합니다.\n",
    "    Args:\n",
    "        data_url (str): 데이터셋의 URL\n",
    "        tokenizer: 텍스트 처리를 위한 토크나이저\n",
    "        batch_size (int): DataLoader의 배치 크기\n",
    "    Returns:\n",
    "        tuple: (train_dataloader, test_dataloader, label_to_id, id_to_label, unique_labels)\n",
    "    \"\"\"\n",
    "    # 데이터셋 로드 및 분할\n",
    "    train_dataset, test_dataset = load_and_split_dataset(data_url)\n",
    "    # 레이블 매핑 생성\n",
    "    label_to_id, id_to_label, unique_labels = create_label_mappings(train_dataset)\n",
    "    # 데이터셋 생성\n",
    "    train_data = TextClassificationDataset(\n",
    "        train_dataset,\n",
    "        tokenizer,\n",
    "        label_to_id\n",
    "    )\n",
    "    test_data = TextClassificationDataset(\n",
    "        test_dataset,\n",
    "        tokenizer,\n",
    "        label_to_id\n",
    "    )\n",
    "    # 데이터로더 생성\n",
    "    train_dataloader = DataLoader(\n",
    "        train_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    test_dataloader = DataLoader(\n",
    "        test_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    return train_dataloader, test_dataloader, label_to_id, id_to_label, unique_labels\n",
    "\n",
    "def get_hyperparameters():\n",
    "    \"\"\"\n",
    "    훈련 하이퍼파라미터를 반환합니다.\n",
    "    Returns:\n",
    "        tuple: (num_epochs, batch_size, learning_rate)\n",
    "    \"\"\"\n",
    "    # 시퀀스 분류가 더 빨리 수렴하므로 더 적은 에포크로 훈련\n",
    "    num_epochs=8\n",
    "    # 대부분의 GPU 메모리에서 잘 작동하는 표준 배치 크기\n",
    "    batch_size=16\n",
    "    # 트랜스포머 미세 튜닝을 위한 표준 학습률\n",
    "    learning_rate=5e-5\n",
    "    return num_epochs, batch_size, learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 576,
     "referenced_widgets": [
      "f67446e2c4994e328560c48969454667",
      "f656ff913c8e4f57a265f2bf1bc63861",
      "89763ebfed314527aa9d1c9fad313a2f",
      "34db32b10db848f1b5bb3d94fefd0b41",
      "9ac8e74f72f84347986f26dff620c852",
      "459cd0331c664a0ebc3f000eb4ad1f7a",
      "a3dc209a166f4af0b1bc42251bb0e5e1",
      "bbbcad8b55124289a6beb0687a90cbb2",
      "fb15b87b0f9c4dc081283b6a882422a9",
      "cd969bdbe11b4ee9b46de0e3ca9e1dd0",
      "add2df4ea5ae47aeb46f689abb02d185",
      "b55e7d036aff4faf80529f9854fb18cf",
      "0471474b42994d9c9cff3387dc02ff68",
      "6498d1ee5c274480810b132bc6a337d8",
      "b0b03ad572854aad96097412fd281618",
      "7a18eb2f97ee479399dfd7f25f100920",
      "fc1455cf31194c2f9d442dc089ddc176",
      "8d95ce1c50a347c4b420a6ac7cab21b6",
      "5bcdf326078147e4a1a24b67498bccb3",
      "32dda78f1ce547f69971aafd13c8a7ca",
      "2501cebdc68042b3a3f359ff02d6a858",
      "bc2e0c936cd3423699b588883504f22e",
      "04b1fe90ec9d48278d89e38d5327601e",
      "f67561863f7a47e395b43add4765d7fd",
      "b1e014090c504085a66ea53013c56303",
      "83b9afdaf39349f6bf159cddd6aada72",
      "f7d4307dd0ca411e8268c44f54d162fc",
      "170844fce3364716b815cb7e275a402e",
      "d45af6326cd04590a5d03e59f8ad1d7b",
      "fc1f92dfa5f1433c9f7adfadf401db49",
      "e081f48f6426454e99bedba4bec723e0",
      "905727b720824d1682e873078f497cc1",
      "0af2415c6e544a1f8c628696d5e0ca55",
      "5746620afd40499c92bbdc3176e8eb84",
      "a4f3cb1195e248ae9d0ddae1064cc5fd",
      "b3daf88207a54106bd8ba36c969f3363",
      "7334062afb764257985d68be03238535",
      "1e997d7d538548598af0f2b686b78714",
      "b4da0bd9374f49a5b464c11d996cbd39",
      "039bb372f97f4b138bc1d2de899859a9",
      "d3b334d63c2746dc839a9ccb65274e5b",
      "1d5d7a6bb97d4cd895f3d25c2a5e23fe",
      "f2f89212019d42b591f9d181526ce36a",
      "63a6f5679b8c4ac38152a9cfbeec8f1f",
      "fbf295450fba4676884a934acbe9eea0",
      "e40bcf79d27946eda59657c97f315261",
      "e046d9752ce645cebd669b9f3a6bbb9f",
      "7eeebe3f4a43493d9abc51208dba0a1d",
      "1ca033bb6cc0497c91b1ac053b9bbfbf",
      "b5c78d23e4e344aba15bd95040b6296e",
      "3b3195d3c5f44a518ef5795894820ebd",
      "7d51403751f24f3bbe7307369476fa7d",
      "6941d10dc25b443384aa0cf82f88467a",
      "02135fc06f4f4d10870fddd17df80569",
      "b832cb49bbd54b278aebfd2166f55113",
      "8a3458d75bfa4223a86a19f7da47b88c",
      "cdfa38b7464d4dd7b6581ecc8b708a9d",
      "7e664139016e435cb6b9799a5b4c1dd9",
      "8399fdc5c2154e35a5f86097ff500a05",
      "2a7a3f1f2cea4d049ec5513443deb333",
      "9ee16e5626774b36a5c81e34c115dc1b",
      "d4b2850802cc4764b6f851179136ced6",
      "88110bb460ba4e00907870ee862b6506",
      "8297d5e2c7bb42d0bd47b4fe6e029351",
      "a01dd767e78b4bd68a8e88b86dbd8731",
      "53d74ee193ec4010a72b817f538e36b7"
     ]
    },
    "id": "tV5env80jwuf",
    "outputId": "2acb193d-9553-4152-8ada-acffe69d999f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f67446e2c4994e328560c48969454667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b55e7d036aff4faf80529f9854fb18cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04b1fe90ec9d48278d89e38d5327601e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5746620afd40499c92bbdc3176e8eb84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf295450fba4676884a934acbe9eea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a3458d75bfa4223a86a19f7da47b88c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "에포크 1/8: 100%|██████████| 1125/1125 [00:55<00:00, 20.21it/s, 손실=0.488]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 손실: 0.4882, 테스트 정확도: 0.9230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "에포크 2/8: 100%|██████████| 1125/1125 [00:53<00:00, 20.86it/s, 손실=0.144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 손실: 0.1437, 테스트 정확도: 0.9310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "에포크 3/8: 100%|██████████| 1125/1125 [00:54<00:00, 20.83it/s, 손실=0.115]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 손실: 0.1149, 테스트 정확도: 0.9410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "에포크 4/8: 100%|██████████| 1125/1125 [00:54<00:00, 20.63it/s, 손실=0.104]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 손실: 0.1038, 테스트 정확도: 0.9395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "에포크 5/8: 100%|██████████| 1125/1125 [00:54<00:00, 20.79it/s, 손실=0.0963]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 손실: 0.0963, 테스트 정확도: 0.9340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "에포크 6/8: 100%|██████████| 1125/1125 [00:54<00:00, 20.82it/s, 손실=0.0851]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 손실: 0.0851, 테스트 정확도: 0.9395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "에포크 7/8: 100%|██████████| 1125/1125 [00:53<00:00, 20.85it/s, 손실=0.0806]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 손실: 0.0806, 테스트 정확도: 0.9400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "에포크 8/8: 100%|██████████| 1125/1125 [00:54<00:00, 20.78it/s, 손실=0.0767]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 손실: 0.0767, 테스트 정확도: 0.9460\n",
      "입력: I'm so happy to be able to finetune an LLM!\n",
      "예측된 감정: joy\n"
     ]
    }
   ],
   "source": [
    "# 재현성을 위해 난수 시드 설정\n",
    "seed = 42\n",
    "set_seed(seed)\n",
    "\n",
    "# 훈련 매개변수 구성\n",
    "data_url = \"https://www.thelmbook.com/data/emotions\"\n",
    "model_name = \"openai-community/gpt2\"\n",
    "\n",
    "# 하이퍼파라미터 가져오기\n",
    "num_epochs, batch_size, learning_rate = get_hyperparameters()\n",
    "\n",
    "# 장치 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 토크나이저 초기화\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 데이터 준비 및 레이블 매핑 가져오기\n",
    "train_loader, test_loader, label_to_id, id_to_label, unique_labels = download_and_prepare_data(\n",
    "    data_url,\n",
    "    tokenizer,\n",
    "    batch_size\n",
    ")\n",
    "\n",
    "# 시퀀스 분류를 위한 모델 초기화\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(unique_labels)\n",
    ").to(device)\n",
    "\n",
    "# 모델의 레이블 처리 구성\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "model.config.id2label = id_to_label\n",
    "model.config.label2id = label_to_id\n",
    "\n",
    "# 옵티마이저 초기화\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 훈련 루프\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"에포크 {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        # 배치를 장치로 이동\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        # 포워드 패스\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        # 백워드 패스 및 최적화\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 메트릭 업데이트\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        progress_bar.set_postfix({\"손실\": total_loss / num_batches})\n",
    "\n",
    "    # 에포크 메트릭 표시\n",
    "    avg_loss = total_loss / num_batches\n",
    "    test_acc = calculate_accuracy(model, test_loader)\n",
    "    print(f\"평균 손실: {avg_loss:.4f}, 테스트 정확도: {test_acc:.4f}\")\n",
    "\n",
    "# 미세 튜닝된 모델 저장\n",
    "model.save_pretrained(\"./finetuned_model\")\n",
    "tokenizer.save_pretrained(\"./finetuned_model\")\n",
    "\n",
    "# 모델 테스트\n",
    "test_input = \"I'm so happy to be able to finetune an LLM!\"\n",
    "test_model(\"./finetuned_model\", test_input)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
